{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "VAE.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "august-laundry",
        "outputId": "e0f09c8a-17e6-4bbd-987a-1974b36d1e92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "import pandas as pd\n",
        "# imports the torch_xla package\n",
        "import os\n",
        "TPU = 'COLAB_TPU_ADDR' in os.environ\n",
        "if TPU:\n",
        "  !pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.7-cp36-cp36m-linux_x86_64.whl\n",
        "  import torch_xla\n",
        "  import torch_xla.core.xla_model as xm\n",
        "\n",
        "\n",
        "torch.manual_seed(42)"
      ],
      "id": "august-laundry",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fdd0769eb70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLwZde_ZSNSf",
        "outputId": "b432c2c8-443c-4d64-8830-514f0a3f5a58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/loodvn/pytorch-chemicalvae.git\n",
        "!mv pytorch-chemicalvae/data data\n",
        "# !ls data"
      ],
      "id": "FLwZde_ZSNSf",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'pytorch-chemicalvae' already exists and is not an empty directory.\n",
            "mv: cannot stat 'pytorch-chemicalvae/data': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "accompanied-speaking"
      },
      "source": [
        "X = np.load('data/train_compressed.npz')['arr_0']\n",
        "Y = np.load('data/Y_reg.npy')\n",
        "# X = np.load('data/X_100.npy')\n",
        "# Y = np.load('data/Y_reg100.npy')"
      ],
      "id": "accompanied-speaking",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "therapeutic-fairy"
      },
      "source": [
        "# Put in load_data\n",
        "from torch.utils.data import DataLoader, TensorDataset, DataLoader, WrappedDataLoader\n",
        "\n",
        "TMP_TRAIN_SIZE = 1000\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "if TMP_TRAIN_SIZE < 0:\n",
        "    TMP_TRAIN_SIZE = Y.shape[0]\n",
        "# 75/25 split\n",
        "valid_idx = int(TMP_TRAIN_SIZE*0.75)\n",
        "x_train, y_train, x_valid, y_valid = map(torch.tensor, (X[:valid_idx], Y[:valid_idx], X[valid_idx:], Y[valid_idx:]))\n",
        "  \n",
        "del(X)  # Takes up too much RAM\n",
        "\n",
        "train_ds = TensorDataset(x_train, y_train)\n",
        "valid_ds = TensorDataset(x_valid, y_valid)\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valid_loader = DataLoader(valid_ds, batch_size=2*BATCH_SIZE)"
      ],
      "id": "therapeutic-fairy",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "least-proceeding"
      },
      "source": [
        "class ChemVAE(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ChemVAE, self).__init__()\n",
        "        \n",
        "        self.latent_dims = 196  # p7, VAEs\n",
        "        self.num_char = 35 # including +1 for padding\n",
        "        \n",
        "        # From Methods/Autoencoder architecture section (p13)\n",
        "        self.enc_cnn1 = nn.Conv1d(in_channels=120, out_channels=9, kernel_size=9)  # 9,9\n",
        "        self.enc_cnn2 = nn.Conv1d(in_channels=9, out_channels=9, kernel_size=9)  # 9,9\n",
        "        self.enc_cnn3 = nn.Conv1d(in_channels=9, out_channels=11, kernel_size=10)  # 10, 11 (filter size, convolutional kernels)\n",
        "        \n",
        "        \n",
        "        self.enc_fc_mu = nn.Linear(11*10, self.latent_dims)  # 11  (out_channels * whatever's left?)\n",
        "        self.enc_fc_var = nn.Linear(11*10, self.latent_dims)  # 11\n",
        "        \n",
        "        \n",
        "        self.dec_gru = nn.GRU(input_size=self.latent_dims, hidden_size=488, num_layers=3, batch_first=True)  # TODO input_size is latent space?\n",
        "#         self.dec_gru_last = nn.GRU(input_size = self.latent_dims, hidden_size=488, )  # output GRU layer had one additional input, corresponding to the character sampled from the softmax output\n",
        "        self.dec_fc  = nn.Linear(488, self.num_char)\n",
        "        \n",
        "        self.property_1 = nn.Linear(self.latent_dims, 1000)\n",
        "        self.property_2 = nn.Linear(1000, 3)\n",
        "        self.property_dropout = nn.Dropout(p=0.2)\n",
        "        \n",
        "        # TODO activation functions? Assuming tanh not relu? Also, difference between F.relu and nn.ReLU?\n",
        "        self.act = F.relu\n",
        "        \n",
        "        \n",
        "    def encode(self, x):\n",
        "#         print(\"initial size:\", x.shape)\n",
        "        x = self.act(self.enc_cnn1(x))\n",
        "#         print(\"initial size:\", x.shape)\n",
        "        x = self.act(self.enc_cnn2(x))\n",
        "        x = self.act(self.enc_cnn3(x))\n",
        "#         print(\"size after enc_cnns:\", x.shape)\n",
        "\n",
        "        x = x.view(x.size(0), -1) # Flatten, Keep batch size\n",
        "        mu = self.enc_fc_mu(x)\n",
        "        var = self.enc_fc_var(x)\n",
        "\n",
        "        return mu, var\n",
        "\n",
        "    def decode(self, z):\n",
        "#         print(\"size before reshape\", z.size)\n",
        "        z = z.view(z.size(0), 1, z.size(-1))  # Expand_dims (1, latent_dim) -> (1, 1, latent_dim)\n",
        "#         print(\"size mid-reshape\", z.size)\n",
        "        z = z.repeat(1, 120, 1)               # Repeat latent*120: (1, 1, latent_dim) -> (1, 120, latent_dim)\n",
        "#         print(\"size after reshape\", z.size)\n",
        "        output, hn = self.dec_gru(z)\n",
        "        softmax = self.dec_fc(output)\n",
        "        softmax = F.softmax(softmax, dim=1)\n",
        "#         print(\"softmax shape:\", softmax.size())\n",
        "        return softmax\n",
        "        \n",
        "    \n",
        "    \n",
        "    # Copied from PyTorch VAE example\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps*std\n",
        "    \n",
        "    def prediction(self, z):\n",
        "        # two fully connected layers of 1000 neurons, dropout rate of 0.2\n",
        "        fc1 = self.act(self.property_dropout(self.property_1(z)))\n",
        "#         print(\"prop1 shape: \", fc1.shape)\n",
        "        pred = self.act(self.property_dropout(self.property_2(fc1)))\n",
        "#         print(\"prop 2 shape\", pred.shape)\n",
        "        \n",
        "        # output: batch size * 3\n",
        "        return pred #.view(pred.size(0))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar, z"
      ],
      "id": "least-proceeding",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "challenging-delta"
      },
      "source": [
        "Training\n",
        "- variational loss (KL divergence) annealed according to sigmoid schedule after 29 epochs, running for a total 120 epochs.\n",
        "- output GRU layer had one additional input, corresponding to the character sampled from the softmax output, trained using teacher forcing\n",
        "\n",
        "Getting output samples from softmax (depending on temperature):\n",
        "https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html#preparing-for-training\n",
        "\n",
        "Pytorch training loop over batches:\n",
        "loss.backward()\n",
        "opt.step()\n",
        "opt.zero_grad()\n",
        "\n",
        "Which reconstruction loss?\n",
        "CE loss?"
      ],
      "id": "challenging-delta"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hispanic-colombia"
      },
      "source": [
        "def one_hot_array(i, n):\n",
        "    return map(int, [ix == i for ix in xrange(n)])\n",
        "\n",
        "def one_hot_index(vec, charset):\n",
        "    return map(charset.index, vec)\n",
        "\n",
        "def from_one_hot_array(vec):\n",
        "    oh = np.where(vec == 1)\n",
        "    if oh[0].shape == (0, ):\n",
        "        return None\n",
        "    return int(oh[0][0])\n",
        "\n",
        "def decode_smiles_from_indexes(vec, charset):\n",
        "    return \"\".join(map(lambda x: charset[x], vec)).strip()\n",
        "\n",
        "charset = ['n',\n",
        " '[',\n",
        " 'o',\n",
        " 'I',\n",
        " '3',\n",
        " 'H',\n",
        " '+',\n",
        " 'S',\n",
        " '@',\n",
        " '8',\n",
        " '4',\n",
        " '1',\n",
        " 's',\n",
        " 'N',\n",
        " 'F',\n",
        " 'P',\n",
        " '/',\n",
        " '=',\n",
        " 'O',\n",
        " 'B',\n",
        " 'C',\n",
        " '\\\\',\n",
        " '(',\n",
        " '-',\n",
        " ']',\n",
        " '6',\n",
        " ')',\n",
        " 'r',\n",
        " '5',\n",
        " '7',\n",
        " '2',\n",
        " '#',\n",
        " 'l',\n",
        " 'c',\n",
        " ' ']"
      ],
      "id": "hispanic-colombia",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acoustic-surgery",
        "outputId": "70f17316-d342-481b-ef97-050650ebd5fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def sigmoid_schedule(time_step, slope=1., start=22):\n",
        "    return float(1 / (1. + np.exp(slope * (start - float(time_step)))))\n",
        "sigmoid_schedule(30)"
      ],
      "id": "acoustic-surgery",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9996646498695336"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "express-stage"
      },
      "source": [
        "# Baseline: Mean prediction\n"
      ],
      "id": "express-stage"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "actual-framework",
        "outputId": "217e0098-1cf5-4e5b-b0ac-2c9f0b9a9053",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# \n",
        "logP = np.mean(np.abs(Y[:,0].mean()-Y[:,0]))\n",
        "print(\"logP baseline: \", logP)\n",
        "QED = np.mean(np.abs(Y[:,1].mean()-Y[:,1]))\n",
        "print(\"QED baseline: \", QED)"
      ],
      "id": "actual-framework",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logP baseline:  1.1381030935900205\n",
            "QED baseline:  0.1121743723222245\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vanilla-detail",
        "outputId": "e83e6702-3fe3-465e-fe29-e9f4c7c34dae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(np.abs(Y.mean(axis=0)-Y)).mean(axis=0)  # logP, QED, SAS"
      ],
      "id": "vanilla-detail",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.13810309, 0.11217437, 0.66557906])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "convenient-virus"
      },
      "source": [
        "## Train"
      ],
      "id": "convenient-virus"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spectacular-boston",
        "outputId": "0a3090af-bdb4-4959-f75c-83823694ca9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Starting training\")\n",
        "# From other pytorch implementation\n",
        "def vae_loss(x_decoded_mean, x, z_mean, z_logvar):\n",
        "    xent_loss = F.binary_cross_entropy(x_decoded_mean, x, reduction='sum')\n",
        "    kl_loss = -0.5 * torch.sum(1 + z_logvar - z_mean.pow(2) - z_logvar.exp())\n",
        "    return xent_loss + kl_loss\n",
        "\n",
        "def xent_loss(x_decoded_mean, x):\n",
        "    return F.binary_cross_entropy(x_decoded_mean, x, reduction='sum')\n",
        "\n",
        "def kl_loss(z_mean, z_logvar):\n",
        "    return -0.5 * torch.sum(1 + z_logvar - z_mean.pow(2) - z_logvar.exp())\n",
        "\n",
        "# prediction loss: mse\n",
        "def pred_loss(y_pred, y_true):\n",
        "    return torch.mean((y_pred - y_true).pow(2)).to(device)\n",
        "\n",
        "def mae(y_pred, y_true):\n",
        "    return torch.mean(torch.abs(y_pred - y_true))\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# device = xm.xla_device()\n",
        "epochs = 30\n",
        "\n",
        "model = ChemVAE().to(device)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# From other pytorch implementation TODO\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, data in enumerate(train_loader):\n",
        "        y_true = data[1].to(device)\n",
        "        data = data[0].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output, mean, logvar, z = model(data)\n",
        "        pred = model.prediction(z)\n",
        "#         print(\"pred:\", pred.shape, \"y: \", y_true.shape)\n",
        "        \n",
        "        if batch_idx==0:\n",
        "              inp = data.cpu().numpy()\n",
        "              outp = output.cpu().detach().numpy()\n",
        "              lab = data.cpu().numpy()\n",
        "              print(\"Input:\")\n",
        "              print(decode_smiles_from_indexes(map(from_one_hot_array, inp[0]), charset))\n",
        "              print(\"Label:\")\n",
        "              print(decode_smiles_from_indexes(map(from_one_hot_array, lab[0]), charset))\n",
        "              sampled = outp[0].reshape(1, 120, len(charset)).argmax(axis=2)[0]\n",
        "              print(\"Output:\")\n",
        "              print(decode_smiles_from_indexes(sampled, charset))\n",
        "\n",
        "        \n",
        "#         print(\"pred loss: \", pred_loss(pred, y_true), \"shape: \", pred_loss(pred, y_true).shape)\n",
        "        sched = torch.tensor(sigmoid_schedule(epoch)).to(device)\n",
        "        loss = sched*kl_loss(mean, logvar) + xent_loss(output, data) + sched*pred_loss(pred, y_true)\n",
        "        # import pdb; pdb.set_trace()\n",
        "        loss.backward()\n",
        "        train_loss += loss\n",
        "        optimizer.step()\n",
        "        if TPU:\n",
        "          xm.mark_step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'epoch {epoch} / batch {batch_idx}\\tFull loss: {loss:.4f}')\n",
        "            pred_mae = mae(pred, y_true)\n",
        "            print(f'epoch {epoch} / batch {batch_idx}\\tPred loss: {pred_mae:.4f}')\n",
        "#     print(f'epoch {epoch}: train loss:', (train_loss / len(train_loader.dataset)))\n",
        "    return train_loss / len(train_loader.dataset)\n",
        "\n",
        "def eval_model():\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      eval_loss = 0\n",
        "      eval_pred_loss = 0\n",
        "      logP_loss = 0\n",
        "      QED_loss = 0\n",
        "\n",
        "      for batch_idx, data in enumerate(valid_loader):\n",
        "        y_true = data[1].to(device)\n",
        "        data = data[0].to(device)\n",
        "        output, mean, logvar, z = model(data)\n",
        "        pred = model.prediction(z)\n",
        "\n",
        "        sched = torch.tensor(sigmoid_schedule(epoch)).to(device)\n",
        "        loss = sched*kl_loss(mean, logvar) + xent_loss(output, data) + sched*pred_loss(pred, y_true)\n",
        "        \n",
        "        eval_loss += loss\n",
        "        eval_pred_loss += pred_loss(pred, y_true)\n",
        "        logP_loss += torch.abs(pred[0] - y_true[0])\n",
        "        QED_loss += torch.abs(pred[0] - y_true[0])\n",
        "\n",
        "    return eval_loss / len(valid_loader.dataset), eval_pred_loss / len(valid_loader.dataset), logP_loss / len(valid_loader.dataset), QED_loss / len(valid_loader.dataset)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_loss = train(epoch)\n",
        "    loss, eval_pred_loss, logP_loss, qed_loss = eval_model()\n",
        "    print(f\"Evaluation loss (training): \\n{loss}, \\n{pred_loss}, \\n{logP_loss}, \\n{qed_loss}\")\n",
        "# print(f\"Total time taken: {(end-start)/1000}s\")"
      ],
      "id": "spectacular-boston",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training\n",
            "Input:\n",
            "444@(F-#r4P+\\-4-O6on6FcFFFFFc6@Fc[F-446FFcF(on\n",
            "Label:\n",
            "444@(F-#r4P+\\-4-O6on6FcFFFFFc6@Fc[F-446FFcF(on\n",
            "Output:\n",
            "\\\\NNNNNNN8888]5555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\n",
            "epoch 1 / batch 0\tFull loss: 38951.2344\n",
            "epoch 1 / batch 0\tPred loss: 2.0051\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gFxiASieFex"
      },
      "source": [
        "## tmp\n",
        "TPU Error: /usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\n",
        "    130     retain_graph: Optional[bool] = None,\n",
        "    131     create_graph: bool = False,\n",
        "--> 132     only_inputs: bool = True,\n",
        "    133     allow_unused: bool = False\n",
        "    134 ) -> Tuple[torch.Tensor, ...]:\n",
        "\n",
        "RuntimeError: vector::_M_range_check: __n (which is 1) >= this->size() (which is 1)\n",
        "\n",
        "Loss after ~10 mins:\n",
        "Evaluation loss (training):  (tensor(513.6445, device='cuda:0', dtype=torch.float64), tensor(0.0252, device='cuda:0', dtype=torch.float64), tensor([0.0208, 0.0050, 0.0183], device='cuda:0', dtype=torch.float64), tensor([0.0208, 0.0050, 0.0183], device='cuda:0', dtype=torch.float64\n"
      ],
      "id": "7gFxiASieFex"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loving-ghost"
      },
      "source": [
        "# Manually push data through network"
      ],
      "id": "loving-ghost"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guided-announcement"
      },
      "source": [
        "example_input = x_train[0]\n",
        "x = example_input\n",
        "x = x.view(1, x.size(0), -1).to(device)\n",
        "print(x.size())\n",
        "mu, logvar = model.encode(x)\n",
        "print(mu.shape, logvar.shape)\n",
        "\n",
        "z = model.reparameterize(mu, logvar)\n",
        "z.shape\n",
        "output = model.decode(z)\n",
        "print(\"decoded shape: \", output.shape)\n",
        "\n",
        "out, m, l, z = model.forward(x)\n",
        "vae_loss(out, x, m, l)"
      ],
      "id": "guided-announcement",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "renewable-soccer"
      },
      "source": [
        "model.prediction(z).shape  # TODO should we still have batch here?"
      ],
      "id": "renewable-soccer",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecological-cargo"
      },
      "source": [
        ""
      ],
      "id": "ecological-cargo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "polar-rouge"
      },
      "source": [
        ""
      ],
      "id": "polar-rouge",
      "execution_count": null,
      "outputs": []
    }
  ]
}